{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import tabulate\n",
    "import csv\n",
    "import pickle\n",
    "from numpy import genfromtxt\n",
    "from recsysNN_utils import *\n",
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_item = pd.read_csv(\"csv/x_item.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dict = defaultdict(dict)\n",
    "count = 0\n",
    "with open('csv/movie_list.csv', newline='',encoding=\"utf8\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for line in reader:\n",
    "            if count == 0:\n",
    "                count += 1  #skip header\n",
    "                #print(line) print\n",
    "            else:\n",
    "                count += 1\n",
    "                movie_id = int(line[0])\n",
    "                movie_dict[movie_id][\"title\"] = line[1]\n",
    "                movie_dict[movie_id][\"genres\"] = line[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_item shape:(5630130, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f'train_item shape:{x_item.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scalerUser = StandardScaler()#scalerUser = StandardScaler()\\nscalerUser.fit(x_user)#scalerUser.fit(user_train)\\nx_user = scalerUser.transform(x_user)#user_train = scalerUser.transform(user_train)\\n\\nscalerTarget = MinMaxScaler((-1, 1))#scalerTarget = MinMaxScaler((-1, 1))\\nscalerTarget.fit(y.values.reshape(-1, 1))#scalerTarget.fit(y_train.reshape(-1, 1))\\ny_train = scalerTarget.transform(y.values.reshape(-1, 1))#y_train = scalerTarget.transform(y_train.reshape(-1, 1))\\n#ynorm_test = scalerTarget.transform(y_test.reshape(-1, 1))\\n\\nprint(np.allclose(unscaled_train_item, scalerItem.inverse_transform(x_item)))\\nprint(np.allclose(unscaled_train_user, scalerUser.inverse_transform(x_user)))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale training data\n",
    "unscaled_train_item = x_item\n",
    "\n",
    "scalerItem = StandardScaler()#scalerItem = StandardScaler()\n",
    "scalerItem.fit(x_item)#scalerItem.fit(item_train)\n",
    "x_item = scalerItem.transform(x_item)#item_train = scalerItem.transform(item_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user_features = 17 - 3\n",
    "num_item_features = 17 - 1\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16)]              0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 32)                57952     \n",
      "                                                                 \n",
      " tf.math.l2_normalize (TFOpL  (None, 32)               0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,952\n",
      "Trainable params: 57,952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_outputs = 32\n",
    "input_item_m = tf.keras.layers.Input(shape=(num_item_features))    # input layer\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "      \n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs),\n",
    "    \n",
    "])\n",
    "vm_m = item_NN(input_item_m)                                       # use the trained item_NN\n",
    "vm_m = tf.linalg.l2_normalize(vm_m, axis=1)                        # incorporate normalization as was done in the original model\n",
    "model_m = tf.keras.Model(input_item_m, vm_m)                                \n",
    "model_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vecs = genfromtxt('csv/item_vecs.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Burak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 1ms/step\n",
      "size of all predicted movie feature vectors: (860, 32)\n"
     ]
    }
   ],
   "source": [
    "scaled_item_vecs = scalerItem.transform(item_vecs)\n",
    "vms = model_m.predict(scaled_item_vecs[:,i_s:])\n",
    "print(f\"size of all predicted movie feature vectors: {vms.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq_dist(a,b):\n",
    "    \"\"\"\n",
    "    Returns the squared distance between two vectors\n",
    "    Args:\n",
    "      a (ndarray (n,)): vector with n features\n",
    "      b (ndarray (n,)): vector with n features\n",
    "    Returns:\n",
    "      d (float) : distance\n",
    "    \"\"\"\n",
    "    n = len(a)\n",
    "    temp = []\n",
    "    d = 0 \n",
    "    temp.append(np.square([a-b]))\n",
    "    d = np.sum(temp)\n",
    "    \n",
    "      \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disp = [[\"movie1\", \"genres\", \"movie2\", \"genres\"]]\\nfor i in range(count):\\n    min_idx = np.argmin(m_dist[i])\\n    movie1_id = int(item_vecs[i,0])\\n    movie2_id = int(item_vecs[min_idx,0])\\n    disp.append( [movie_dict[movie1_id][\\'title\\'], movie_dict[movie1_id][\\'genres\\'],\\n                  movie_dict[movie2_id][\\'title\\'], movie_dict[movie1_id][\\'genres\\']]\\n               )\\ntable = tabulate.tabulate(disp, tablefmt=\\'html\\', headers=\"firstrow\")\\ntable'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 50  # number of movies to display\n",
    "dim = len(vms)\n",
    "dist = np.zeros((dim,dim))\n",
    "\n",
    "for i in range(dim):\n",
    "    for j in range(dim):\n",
    "        dist[i,j] = sq_dist(vms[i, :], vms[j, :])\n",
    "        \n",
    "m_dist = ma.masked_array(dist, mask=np.identity(dist.shape[0]))  # mask the diagonal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/m_dist.pickle', 'wb') as f:\n",
    "    # Dump the dictionary into the file using pickle\n",
    "    pickle.dump(m_dist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/movie_dict.pickle', 'wb') as f:\n",
    "    # Dump the dictionary into the file using pickle\n",
    "    pickle.dump(movie_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([138, 348, 161, 544,  28,  35, 621,  89, 458, 154], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(m_dist[10])[::1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Troy (2004)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_dict[item_vecs[676,0]]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hero (Ying xiong) (2002)\n",
      "Gladiator (2000)\n",
      "Last Samurai, The (2003)\n",
      "Into the Wild (2007)\n",
      "King Kong (2005)\n",
      "Thor (2011)\n",
      "Harry Potter and the Order of the Phoenix (2007)\n",
      "Apollo 13 (1995)\n",
      "The Count of Monte Cristo (2002)\n",
      "Dances with Wolves (1990)\n"
     ]
    }
   ],
   "source": [
    "for i in np.argsort(m_dist[676])[::1][:10]:\n",
    "    print(movie_dict[item_vecs[i,0]]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13f3ce89a5df2ac5a13e4cc62c988721835be963b086d264dfe782dec54fd990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

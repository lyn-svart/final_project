{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import tabulate\n",
    "import csv\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_user = pd.read_csv(\"csv/x_train_user.csv\")\n",
    "x_train_item = pd.read_csv(\"csv/x_train_item.csv\")\n",
    "y_train = pd.read_csv(\"csv/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dict = defaultdict(dict)\n",
    "count = 0\n",
    "with open('csv/movie_list.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for line in reader:\n",
    "            if count == 0:\n",
    "                count += 1  #skip header\n",
    "                #print(line) print\n",
    "            else:\n",
    "                count += 1\n",
    "                movie_id = int(line[0])\n",
    "                movie_dict[movie_id][\"title\"] = line[1]\n",
    "                movie_dict[movie_id][\"genres\"] = line[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_user shape:(66657, 22)\n",
      "train_item shape:(66657, 22)\n",
      "y_train shape:(66657, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'train_user shape:{x_train_user.shape}')\n",
    "print(f'train_item shape:{x_train_item.shape}')\n",
    "print(f'y_train shape:{y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# scale training data\n",
    "unscaled_train_item = x_train_item\n",
    "unscaled_train_user = x_train_user\n",
    "y_train_unscaled    = y_train\n",
    "\n",
    "scalerItem = StandardScaler()#scalerItem = StandardScaler()\n",
    "scalerItem.fit(x_train_item)#scalerItem.fit(item_train)\n",
    "x_train_item = scalerItem.transform(x_train_item)#item_train = scalerItem.transform(item_train)\n",
    "\n",
    "scalerUser = StandardScaler()#scalerUser = StandardScaler()\n",
    "scalerUser.fit(x_train_user)#scalerUser.fit(user_train)\n",
    "x_train_user = scalerUser.transform(x_train_user)#user_train = scalerUser.transform(user_train)\n",
    "\n",
    "scalerTarget = MinMaxScaler((-1, 1))#scalerTarget = MinMaxScaler((-1, 1))\n",
    "scalerTarget.fit(y_train.values.reshape(-1, 1))#scalerTarget.fit(y_train.reshape(-1, 1))\n",
    "y_train = scalerTarget.transform(y_train.values.reshape(-1, 1))#y_train = scalerTarget.transform(y_train.reshape(-1, 1))\n",
    "#ynorm_test = scalerTarget.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(np.allclose(unscaled_train_item, scalerItem.inverse_transform(x_train_item)))\n",
    "print(np.allclose(unscaled_train_user, scalerUser.inverse_transform(x_train_user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie/item training data shape: (53325, 22)\n",
      "movie/item test data shape: (13332, 22)\n",
      "movie/user training data shape: (53325, 22)\n",
      "movie/user test data shape: (13332, 22)\n"
     ]
    }
   ],
   "source": [
    "x_train_item, item_test = train_test_split(x_train_item, train_size=0.80, shuffle=True, random_state=1)\n",
    "x_train_user, user_test = train_test_split(x_train_user, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)\n",
    "print(f\"movie/item training data shape: {x_train_item.shape}\")\n",
    "print(f\"movie/item test data shape: {item_test.shape}\")\n",
    "print(f\"movie/user training data shape: {x_train_user.shape}\")\n",
    "print(f\"movie/user test data shape: {user_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user_features = x_train_user.shape[1] - 3\n",
    "num_item_features = x_train_item.shape[1] - 1\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 19)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 21)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 32)           42144       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 32)           42656       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize (TFOpLamb  (None, 32)          0           ['sequential[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_1 (TFOpLa  (None, 32)          0           ['sequential_1[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['tf.math.l2_normalize[0][0]',   \n",
      "                                                                  'tf.math.l2_normalize_1[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 84,800\n",
      "Trainable params: 84,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_outputs = 32\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###     \n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs),\n",
    "  \n",
    "    ### END CODE HERE ###  \n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###     \n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs),\n",
    "    \n",
    "  \n",
    "  \n",
    "    ### END CODE HERE ###  \n",
    "])\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = tf.keras.Model([input_user, input_item], output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=cost_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1667/1667 [==============================] - 8s 3ms/step - loss: 0.1701\n",
      "Epoch 2/30\n",
      "1667/1667 [==============================] - 6s 4ms/step - loss: 0.1667\n",
      "Epoch 3/30\n",
      "1667/1667 [==============================] - 6s 4ms/step - loss: 0.1662\n",
      "Epoch 4/30\n",
      "1667/1667 [==============================] - 6s 3ms/step - loss: 0.1657\n",
      "Epoch 5/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1654\n",
      "Epoch 6/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1650\n",
      "Epoch 7/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1647\n",
      "Epoch 8/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1644\n",
      "Epoch 9/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1643\n",
      "Epoch 10/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1642\n",
      "Epoch 11/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1640\n",
      "Epoch 12/30\n",
      "1667/1667 [==============================] - 4s 3ms/step - loss: 0.1637\n",
      "Epoch 13/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1636\n",
      "Epoch 14/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1635\n",
      "Epoch 15/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1633\n",
      "Epoch 16/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1632\n",
      "Epoch 17/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1631\n",
      "Epoch 18/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1631\n",
      "Epoch 19/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1629\n",
      "Epoch 20/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1627\n",
      "Epoch 21/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1626\n",
      "Epoch 22/30\n",
      "1667/1667 [==============================] - 4s 3ms/step - loss: 0.1625\n",
      "Epoch 23/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1624\n",
      "Epoch 24/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1623\n",
      "Epoch 25/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1622\n",
      "Epoch 26/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1622\n",
      "Epoch 27/30\n",
      "1667/1667 [==============================] - 4s 3ms/step - loss: 0.1621\n",
      "Epoch 28/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1621\n",
      "Epoch 29/30\n",
      "1667/1667 [==============================] - 4s 3ms/step - loss: 0.1618\n",
      "Epoch 30/30\n",
      "1667/1667 [==============================] - 5s 3ms/step - loss: 0.1619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b370e2bdf0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.fit([x_train_user[:, u_s:], x_train_item[:, i_s:]], y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 1s 2ms/step - loss: 0.1644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16437526047229767"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([user_test[:, u_s:], item_test[:, i_s:]], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 0.0\n",
    "new_action = 5.0\n",
    "new_adventure = 5.0\n",
    "new_animation = 0.0\n",
    "new_childrens = 0.0\n",
    "new_comedy = 0.0\n",
    "new_crime = 4.0\n",
    "new_documentary = 0.0\n",
    "new_drama = 0.0\n",
    "new_fantasy = 0.0\n",
    "new_filmnoir = 0.0 ##\n",
    "new_horror = 0.0\n",
    "new_imax = 0.0 ##\n",
    "new_musical = 0.0 ##\n",
    "new_mystery = 0.0\n",
    "new_romance = 0.0\n",
    "new_scifi = 0.0\n",
    "new_thriller = 0.0\n",
    "new_western = 5.0 ##\n",
    "new_war = 0.0 ##\n",
    "new_rating_count = 3\n",
    "#user id,rating count,rating ave,Action,Adventure,Animation,Children,Comedy,Crime,Documentary,Drama,Fantasy,***film-noir**Horror,**imax**,***musical***Mystery,Romance,Sci-Fi,Thriller***war***,***western***\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_filmnoir, new_horror, new_imax, new_musical, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller, new_western, new_war]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_vecs(user_vec, num_items):\n",
    "    \"\"\" given a user vector return:\n",
    "        user predict maxtrix to match the size of item_vecs \"\"\"\n",
    "    user_vecs = np.tile(user_vec, (num_items, 1))\n",
    "    return user_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vecs = genfromtxt('./csv/item_vecs.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred_movies(y_p, item, movie_dict, maxcount=10):\n",
    "    \"\"\" print results of prediction of a new user. inputs are expected to be in\n",
    "        sorted order, unscaled. \"\"\"\n",
    "    count = 0\n",
    "    disp = [[\"y_p\", \"movie id\", \"rating ave\", \"title\", \"genres\"]]\n",
    "\n",
    "    for i in range(0, y_p.shape[0]):\n",
    "        if count == maxcount:\n",
    "            break\n",
    "        count += 1\n",
    "        movie_id = item[i, 0].astype(int)\n",
    "        disp.append([np.around(y_p[i, 0], 1), item[i, 0].astype(int), np.around(item[i, 2].astype(float), 1),\n",
    "                     movie_dict[movie_id]['title'], movie_dict[movie_id]['genres']])\n",
    "\n",
    "    table = tabulate.tabulate(disp, tablefmt='html', headers=\"firstrow\")\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/39 [==================>...........] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\burak\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\burak\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                 </th><th>genres                                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      1262</td><td style=\"text-align: right;\">         4.1</td><td>Great Escape, The (1963)              </td><td>Action|Adventure|Drama|War              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">       594</td><td style=\"text-align: right;\">         3.6</td><td>Snow White and the Seven Dwarfs (1937)</td><td>Animation|Children|Drama|Fantasy|Musical</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      1250</td><td style=\"text-align: right;\">         4.1</td><td>Bridge on the River Kwai, The (1957)  </td><td>Adventure|Drama|War                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2410</td><td style=\"text-align: right;\">         2.7</td><td>Rocky III (1982)                      </td><td>Action|Drama                            </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      1385</td><td style=\"text-align: right;\">         2.9</td><td>Under Siege (1992)                    </td><td>Action|Drama|Thriller                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2411</td><td style=\"text-align: right;\">         2.7</td><td>Rocky IV (1985)                       </td><td>Action|Drama                            </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      1204</td><td style=\"text-align: right;\">         4.3</td><td>Lawrence of Arabia (1962)             </td><td>Adventure|Drama|War                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2944</td><td style=\"text-align: right;\">         4  </td><td>Dirty Dozen, The (1967)               </td><td>Action|Drama|War                        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2018</td><td style=\"text-align: right;\">         3.4</td><td>Bambi (1942)                          </td><td>Animation|Children|Drama                </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2409</td><td style=\"text-align: right;\">         3.2</td><td>Rocky II (1979)                       </td><td>Action|Drama                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">  y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                 </th><th>genres                                  </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      1262</td><td style=\"text-align: right;\">         4.1</td><td>Great Escape, The (1963)              </td><td>Action|Adventure|Drama|War              </td></tr>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">       594</td><td style=\"text-align: right;\">         3.6</td><td>Snow White and the Seven Dwarfs (1937)</td><td>Animation|Children|Drama|Fantasy|Musical</td></tr>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      1250</td><td style=\"text-align: right;\">         4.1</td><td>Bridge on the River Kwai, The (1957)  </td><td>Adventure|Drama|War                     </td></tr>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2410</td><td style=\"text-align: right;\">         2.7</td><td>Rocky III (1982)                      </td><td>Action|Drama                            </td></tr>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      1385</td><td style=\"text-align: right;\">         2.9</td><td>Under Siege (1992)                    </td><td>Action|Drama|Thriller                   </td></tr>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2411</td><td style=\"text-align: right;\">         2.7</td><td>Rocky IV (1985)                       </td><td>Action|Drama                            </td></tr>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      1204</td><td style=\"text-align: right;\">         4.3</td><td>Lawrence of Arabia (1962)             </td><td>Adventure|Drama|War                     </td></tr>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2944</td><td style=\"text-align: right;\">         4  </td><td>Dirty Dozen, The (1967)               </td><td>Action|Drama|War                        </td></tr>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2018</td><td style=\"text-align: right;\">         3.4</td><td>Bambi (1942)                          </td><td>Animation|Children|Drama                </td></tr>\\n<tr><td style=\"text-align: right;\">  2.8</td><td style=\"text-align: right;\">      2409</td><td style=\"text-align: right;\">         3.2</td><td>Rocky II (1979)                       </td><td>Action|Drama                            </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate and replicate the user vector to match the number movies in the data set.\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "\n",
    "# scale our user and item vectors\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "\n",
    "# make a prediction\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "\n",
    "# unscale y prediction \n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "\n",
    "# sort the results, highest prediction first\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "\n",
    "print_pred_movies(sorted_ypu, sorted_items, movie_dict, maxcount = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100835, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scalerItem.inverse_transform(x_train_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100835, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scalerUser.inverse_transform(x_train_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100835, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(uncaled_train_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100835, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(unclaed_train_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
